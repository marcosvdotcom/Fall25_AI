---
title: What is Generative AI?
nav: What is AI?
---
## What is AI?

At it's core, generative AI is still just traditional computing, just with a lot more processor power.

Online large language model AI's, such as ChatGPT, run your request to a physical warehouse where there are many thousands of graphic cards powering servers, which then run the HUGE calculations necessary to analyze your input and formulate a conversational response, all using prediction. Different models are trained on different datasets, and weigh your input, referred to as a "token", differently once it enters the AI's decision making matrix. A key difference between models is the secret recipes they use to weigh tokens, which shapes how the model replies. 

{% include figure.html img="https://eu-images.contentstack.com/v3/assets/blt8eb3cdfc1fce5194/bltb2f3b9adcdc7b2ea/6621179bdf2010ac670866be/nvidia_20a100_20ampere_20gpu.jpg" caption="A NVIDIA graphic processing chip, as is commonly used in data centers." width="75%" %}

{% include figure.html img="https://imageio.forbes.com/specials-images/imageserve/665e32418239c153a911b350/0x0.jpg" caption="AI Data center" width="75%" %}

## What's the big deal about probability?

AI computing _is_ different in that it works off a prediction and probability model, versus a calculation or computation. Think of the difference between a discipline like statistics, versus computation or arithmetic. In computational thinking, for instance 2+3=5, the computer performs a fixed operation to a set outcome - it adds 2+3 and equals this to 5. You never get a different answer, and in fact you wouldn't want to!

A probabilistic software, like most generative AI, would instead look at how often 2+3 equaled 5, according to occurrences in it's training data, and based on the probabilities it learned there, it would make predictions, or educated guesses. Because of this, if the AI has been trained on data that says 2+3 equals 17, or "cat", or "pink zebra", that information will always override the true answer of "5".

At present (Fall 2025), generative AI models are _always_ guessing. In fact, it turns out large language models use strategies similar to standardized test takers, because these models are rewarded for guessing confidently, even with incorrect or made-up information, rather than creating the equivalent of a blank answer and saying "I don't know."

## What is AI _not_?

- Alive
- Thinking
- Generative, it remixes things it has already seen and by definition cannot truly create anything

Much of the language around AI conveys a sense of intelligence, thinking, or even life. It's important to remember that AI is not alive, does not possess consciousness, and is not able to think, hallucinate, or even lie, as that would require consciousness. These words instead describe our human experience and interpretation of what is essentially a sophisticated probability simulator. 